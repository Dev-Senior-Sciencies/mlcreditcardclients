{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\Downloads\\projetos\\py\\mlcreditcardclients\\.env\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "2025/12/28 04:58:01 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/28 04:58:01 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/28 04:58:01 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/28 04:58:01 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/28 04:58:01 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/28 04:58:01 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "Dense = tf.keras.layers.Dense\n",
    "Input = tf.keras.layers.Input\n",
    "Sequential = tf.keras.Sequential\n",
    "MeanSquaredError = tf.keras.losses.MeanSquaredError\n",
    "BinaryCrossentropy = tf.keras.losses.BinaryCrossentropy\n",
    "Sigmoid = tf.keras.activations.sigmoid\n",
    "\n",
    "file_path = os.getcwd()\n",
    "\n",
    "conf = OmegaConf.load(os.path.join(file_path, \"..\", \"src\", \"config.yml\"))\n",
    "\n",
    "mlflow.set_experiment(conf[\"tracking_uri\"][\"experiment_name\"])\n",
    "\n",
    "data_path = os.path.join(file_path, \"..\", \"data\", \"UCI_Credit_Card.csv\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "lambdas = [0, 1e-5, 1e-4, 5e-4, 1e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, params):\n",
    "\n",
    "    # ===============================\n",
    "    # TARGET\n",
    "    # ===============================\n",
    "    y = df['default.payment.next.month']\n",
    "\n",
    "    # ===============================\n",
    "    # FEATURES\n",
    "    # ===============================\n",
    "    X = df[\n",
    "        [\n",
    "            'LIMIT_BAL',\n",
    "            'SEX',\n",
    "            'EDUCATION',\n",
    "            'MARRIAGE',\n",
    "            'AGE',\n",
    "            'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "            'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',\n",
    "            'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "            'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
    "            'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    # ===============================\n",
    "    # DEFINI√á√ÉO DOS TIPOS\n",
    "    # ===============================\n",
    "    binary_features = ['SEX']\n",
    "    categorical_features = ['EDUCATION', 'MARRIAGE']\n",
    "    numerical_features = [\n",
    "        'LIMIT_BAL',\n",
    "        'AGE',\n",
    "        'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "        'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',\n",
    "        'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "        'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
    "        'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'\n",
    "    ]\n",
    "    \n",
    "    # ===============================\n",
    "    # PREPROCESSAMENTO\n",
    "    # ===============================\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('bin', MinMaxScaler(), binary_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "            ('num', MinMaxScaler(), numerical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # ===============================\n",
    "    # SPLIT\n",
    "    # ===============================\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=params[\"test_size\"],\n",
    "        random_state=params[\"random_state\"],\n",
    "        stratify=y\n",
    "    )\n",
    "    \n",
    "\t# ===============================\n",
    "    # TRANSFORMAR DADOS\n",
    "    # ===============================\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "\n",
    "    results = []\n",
    "        \n",
    "    # ===============================\n",
    "    # TREINAR V√ÅRIOS MODELOS (LAMBDA)\n",
    "    # ===============================\n",
    "    for lambda_ in lambdas:\n",
    "                 \n",
    "        model = Sequential([\n",
    "\t\t\t\tDense(64, activation = 'relu', name = 'layer1', kernel_regularizer=tf.keras.regularizers.l2(lambda_)),\n",
    "\t\t\t\tDense(32, activation = 'relu', name = 'layer2', kernel_regularizer=tf.keras.regularizers.l2(lambda_)),\n",
    "\t\t\t\tDense(1, activation = 'linear', name = 'layer3')\n",
    "\t\t], name = 'Credit_Default_Model')\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(\n",
    "                learning_rate=params[\"learning_rate\"]\n",
    "            ),\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=params[\"epochs\"],\n",
    "            verbose=params[\"verbose\"]\n",
    "        )\n",
    "\n",
    "        # ===============================\n",
    "        # AVALIA√á√ÉO\n",
    "        # ===============================\n",
    "        logits = model(X_test)\n",
    "        y_pred_proba = tf.nn.sigmoid(logits).numpy().ravel()\n",
    "        y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "        results.append({\n",
    "            \"lambda\": lambda_,\n",
    "            \"accuracy\": acc,\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"model\": model\n",
    "        })\n",
    "\n",
    "        print(f\"Œª={lambda_:.3f} | Accuracy={acc:.4f} | ROC-AUC={roc_auc:.4f}\")\n",
    "\n",
    "    # ===============================\n",
    "    # MELHOR MODELO\n",
    "    # ===============================\n",
    "    best_model = max(results, key=lambda x: x[\"roc_auc\"])\n",
    "\n",
    "    print(\"\\nüèÜ Melhor Modelo:\")\n",
    "    print(f\"Lambda: {best_model['lambda']}\")\n",
    "    print(f\"ROC-AUC: {best_model['roc_auc']:.4f}\")\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Load data\n",
    "    train(df, conf[\"parameters\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
