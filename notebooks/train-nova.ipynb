{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "Dense = tf.keras.layers.Dense\n",
    "Input = tf.keras.layers.Input\n",
    "Sequential = tf.keras.Sequential\n",
    "MeanSquaredError = tf.keras.losses.MeanSquaredError\n",
    "BinaryCrossentropy = tf.keras.losses.BinaryCrossentropy\n",
    "Sigmoid = tf.keras.activations.sigmoid\n",
    "\n",
    "file_path = os.getcwd()\n",
    "\n",
    "conf = OmegaConf.load(os.path.join(file_path, \"..\", \"src\", \"config.yml\"))\n",
    "\n",
    "data_path = os.path.join(file_path, \"..\", \"data\", \"UCI_Credit_Card.csv\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "lambdas = [0, 1e-5, 1e-4, 5e-4, 1e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_percent_paid_features(df):\n",
    "    for i in range(1, 7):\n",
    "        df[f\"PCT_PAID_{i}\"] = np.where(\n",
    "            df[f\"BILL_AMT{i}\"] > 0,\n",
    "            df[f\"PAY_AMT{i}\"] / df[f\"BILL_AMT{i}\"],\n",
    "            0\n",
    "        )\n",
    "\n",
    "    df[\"PCT_PAID_MEAN\"] = df[[f\"PCT_PAID_{i}\" for i in range(1, 7)]].mean(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_credit_utilization(df):\n",
    "    bill_cols = [f\"BILL_AMT{i}\" for i in range(1, 7)]\n",
    "    df[\"BILL_MEAN\"] = df[bill_cols].mean(axis=1)\n",
    "\n",
    "    df[\"CREDIT_UTILIZATION\"] = np.where(\n",
    "        df[\"LIMIT_BAL\"] > 0,\n",
    "        df[\"BILL_MEAN\"] / df[\"LIMIT_BAL\"],\n",
    "        0\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_pay_delay_features(df):\n",
    "    pay_cols = ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "    df[\"PAY_DELAY_MEAN\"] = df[pay_cols].mean(axis=1)\n",
    "    df[\"PAY_DELAY_MAX\"] = df[pay_cols].max(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    df = create_percent_paid_features(df)\n",
    "    df = create_credit_utilization(df)\n",
    "    df = create_pay_delay_features(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, params):\n",
    "\n",
    "    df = feature_engineering(df)\n",
    "    # ===============================\n",
    "    # TARGET\n",
    "    # ===============================\n",
    "    y = df['default.payment.next.month']\n",
    "\n",
    "\n",
    "    # ===============================\n",
    "    # FEATURES\n",
    "    # ===============================\n",
    "    X = df[\n",
    "        [\n",
    "            'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE',\n",
    "            'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "            'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',\n",
    "            'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "            'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
    "            'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
    "            'PCT_PAID_MEAN',\n",
    "            'CREDIT_UTILIZATION',\n",
    "            'PAY_DELAY_MEAN',\n",
    "            'PAY_DELAY_MAX'\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    # ===============================\n",
    "    # DEFINIO DOS TIPOS\n",
    "    # ===============================\n",
    "    binary_features = ['SEX']\n",
    "    categorical_features = ['EDUCATION', 'MARRIAGE']\n",
    "    numerical_features = [col for col in X.columns if col not in binary_features + categorical_features]\n",
    "    # numerical_features = [\n",
    "    #     'LIMIT_BAL',\n",
    "    #     'AGE',\n",
    "    #     'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "    #     'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',\n",
    "    #     'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "    #     'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
    "    #     'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'\n",
    "    # ]\n",
    "    \n",
    "    # ===============================\n",
    "    # PREPROCESSAMENTO\n",
    "    # ===============================\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('bin', MinMaxScaler(), binary_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "            ('num', MinMaxScaler(), numerical_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # ===============================\n",
    "    # SPLIT\n",
    "    # ===============================\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=params[\"test_size\"],\n",
    "        random_state=params[\"random_state\"],\n",
    "        stratify=y\n",
    "    )\n",
    "    \n",
    "    # ===============================\n",
    "    # TRANSFORMAR DADOS\n",
    "    # ===============================\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_lambda(X, y, lambdas, params):\n",
    "\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=params[\"cv_folds\"],\n",
    "        shuffle=True,\n",
    "        random_state=params[\"random_state\"]\n",
    "    )\n",
    "\n",
    "    best_lambda = None\n",
    "    best_auc = -np.inf\n",
    "\n",
    "    for lambda_ in lambdas:\n",
    "        aucs = []\n",
    "\n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "\n",
    "            X_tr, X_val = X[train_idx], X[val_idx]\n",
    "            y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            model = Sequential([\n",
    "                Dense(64, activation='relu',\n",
    "                      kernel_regularizer=tf.keras.regularizers.l2(lambda_)),\n",
    "                Dense(32, activation='relu',\n",
    "                      kernel_regularizer=tf.keras.regularizers.l2(lambda_)),\n",
    "                Dense(1, activation='linear')\n",
    "            ])\n",
    "\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(\n",
    "                    learning_rate=params[\"learning_rate\"]\n",
    "                ),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            )\n",
    "\n",
    "            model.fit(\n",
    "                X_tr,\n",
    "                y_tr,\n",
    "                epochs=params[\"epochs_cross\"],\n",
    "                verbose=params[\"verbose\"]\n",
    "            )\n",
    "\n",
    "            logits = model(X_val)\n",
    "            y_pred_proba = tf.nn.sigmoid(logits).numpy().ravel()\n",
    "\n",
    "            auc = roc_auc_score(y_val, y_pred_proba)\n",
    "            aucs.append(auc)\n",
    "\n",
    "        mean_auc = np.mean(aucs)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        print(f\"[CV] 位={lambda_:.5f} | AUC={mean_auc:.4f} 卤 {std_auc:.4f}\")\n",
    "\n",
    "        if mean_auc > best_auc:\n",
    "            best_auc = mean_auc\n",
    "            best_lambda = lambda_\n",
    "\n",
    "\n",
    "    return best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(X_train, X_test, y_train, y_test, best_lambda, params):\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(best_lambda)),\n",
    "        Dense(32, activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(best_lambda)),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=params[\"learning_rate\"]\n",
    "        ),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=params[\"epochs\"],\n",
    "        verbose=params[\"verbose\"]\n",
    "    )\n",
    "\n",
    "    logits = model(X_test)\n",
    "    y_pred_proba = tf.nn.sigmoid(logits).numpy().ravel()\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    print(\"\\n TEST SET FINAL\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] 位=0.00000 | AUC=0.7685 卤 0.0062\n",
      "[CV] 位=0.00001 | AUC=0.7673 卤 0.0070\n",
      "[CV] 位=0.00010 | AUC=0.7637 卤 0.0071\n",
      "[CV] 位=0.00050 | AUC=0.7515 卤 0.0069\n",
      "[CV] 位=0.00100 | AUC=0.7495 卤 0.0140\n",
      " Melhor lambda escolhido via CV: 0.0e+00\n",
      "\n",
      " TEST SET FINAL\n",
      "Accuracy: 0.8130\n",
      "ROC-AUC: 0.7673\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "     \n",
    "    # Prepara莽茫o dos dados\n",
    "    X_train, X_test, y_train, y_test = prepare_data(df, conf[\"parameters\"])\n",
    "\n",
    "    best_lambda = cross_validate_lambda(X_train, y_train, lambdas, conf[\"parameters\"])\n",
    "\n",
    "    print(f\" Melhor lambda escolhido via CV: {best_lambda:.1e}\")\n",
    "\n",
    "    train_final_model(X_train, X_test, y_train, y_test, best_lambda, conf[\"parameters\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
